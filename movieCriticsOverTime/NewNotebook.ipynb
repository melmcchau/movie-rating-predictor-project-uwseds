{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CleanData.py\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\"\"\"pre data cleaning for reviews data\"\"\"\n",
    "def clean_reviews(REVIEWS):\n",
    "    REVIEWS = REVIEWS[~REVIEWS.quote.isnull()]\n",
    "    REVIEWS = REVIEWS[REVIEWS.fresh != 'none']\n",
    "    REVIEWS = REVIEWS[REVIEWS.quote.str.len() > 0]\n",
    "    REVIEWS['review_date'] = pd.to_datetime(REVIEWS['review_date']).dt.date\n",
    "    REVIEWS_CLEAN = REVIEWS.drop(['link'], axis=1)\n",
    "    return REVIEWS_CLEAN\n",
    "\n",
    "\"\"\" pre data cleaning for movies data\"\"\"\n",
    "def clean_movies(MOVIES):\n",
    "    MOVIES = MOVIES.drop(['imdbPictureURL', 'spanishTitle', 'rtPictureURL'], axis=1)\n",
    "    MOVIES['rtAllCriticsRating'] = MOVIES['rtAllCriticsRating'].apply(pd.to_numeric, errors='drop')\n",
    "    MOVIES['rtAllCriticsNumReviews'] = MOVIES['rtAllCriticsNumReviews'].apply(pd.to_numeric, errors='drop')\n",
    "    MOVIES['rtAudienceRating'] = MOVIES['rtAudienceRating'].apply(pd.to_numeric, errors='drop')\n",
    "    SUB_MOVIES = MOVIES[['title', 'imdbID', 'year', 'rtID', 'rtAllCriticsRating', 'rtAllCriticsNumReviews', 'rtAudienceNumRatings', 'rtAudienceScore']]\n",
    "    return SUB_MOVIES\n",
    "\n",
    "def merge_movies_reviews(REVIEWS,SUB_MOVIES):\n",
    "    REVIEWS_MERGE = REVIEWS_CLEAN.merge(SUB_MOVIES, left_on='imdb', right_on='imdbID', how='left',suffixes=('_review', '_movie'))   \n",
    "    return REVIEWS_MERGE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OverallRating.py\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "import matplotlib.pyplot as plt\n",
    "import mpld3\n",
    "import webbrowser\n",
    "\n",
    "\n",
    "def draw_trend_line_median_year(SUB_MOVIES,start_year,end_year):\n",
    "    \"\"\"\n",
    "    Descripion:\n",
    "    @param:\n",
    "    @return:\n",
    "    \"\"\"\n",
    "    \n",
    "    year_median = SUB_MOVIES.groupby('year')['rtAllCriticsRating'].median().reset_index()\n",
    "    year_show = year_median[year_median['year'] >= start_year]\n",
    "    year_show = year_show[year_median['year'] <= end_year]\n",
    "\n",
    "    selection = alt.selection_interval(bind='scales')\n",
    "\n",
    "    chart_overall = alt.Chart(year_show).mark_line().encode(\n",
    "    alt.Y('rtAllCriticsRating:Q',\n",
    "        scale=alt.Scale(domain=(0, 10))\n",
    "    ),\n",
    "    x='year:N',\n",
    "    tooltip=['rtAllCriticsRating:Q','year']).add_selection(selection).properties(\n",
    "    width=500,\n",
    "    height=200\n",
    "    )\n",
    "    \n",
    "    chart_overall.save(\"overallchart.html\")\n",
    "    return chart_overall\n",
    "    \n",
    "\n",
    "def top5_critic_per_year(REVIEWS_MERGE,interest_year):\n",
    "    \"\"\"\n",
    "    Descripion:\n",
    "    @param:\n",
    "    @return:\n",
    "    \"\"\"\n",
    "    Group_Aggregation = REVIEWS_MERGE[['critic', 'publication', \n",
    "                       'year', 'quote']].groupby(['critic','year']).agg({ \n",
    "                         'quote': ['count']}).reset_index()\n",
    "    \n",
    "    Group_Aggregation = Group_Aggregation[(Group_Aggregation['year'] == interest_year)]\n",
    "    Top_five = Group_Aggregation.sort_values(by=[('quote','count')], \n",
    "                                            ascending = False)[:5].reset_index(drop =True)\n",
    "\n",
    "    top_critics = list(Top_five['critic'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return top_critics\n",
    "    return REVIEWS_MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SentimentAnalysis.py\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import sentiments_nrc\n",
    "import re\n",
    "from sentiments_nrc import SENTIMENTS\n",
    "from sentiments_nrc import EMOTIONS\n",
    "\n",
    "MOVIES = pd.read_csv(\"../data/movies.dat\", delimiter='\\t')\n",
    "REVIEWS = pd.read_csv('../data/reviews.csv')\n",
    "\n",
    "EMOTIONS = ['positive', 'negative', 'anger', \n",
    "            'anticipation', 'disgust', 'fear', \n",
    "            'joy', 'sadness', 'surprise', 'trust']\n",
    "\n",
    "def grab_quotes(REVIEWS_MERGE,top_critics,interest_year):\n",
    "    quote = pd.DataFrame()\n",
    "    for name in top_critics:\n",
    "        critic_quote = REVIEWS_MERGE[['critic','quote','year']]\n",
    "        sub_quote = critic_quote[(critic_quote['critic'] == name) & (critic_quote['year'] == interest_year)]\n",
    "    #   print(len(sub_quote))\n",
    "        quote = quote.append(sub_quote,ignore_index=True)\n",
    "        quote = quote.groupby('critic')['quote'].apply(' '.join).reset_index()\n",
    "    return quote\n",
    "    \n",
    "def analyze_quote(quote,top_critics):\n",
    "    res = pd.DataFrame()\n",
    "    for name in top_critics:\n",
    "        content = quote[quote['critic'] == name]['quote'].values[0]\n",
    "#         content=quote.groupby('critic')['quote'].apply(' '.join).reset_index()['quote']\n",
    "        Split_String=re.split(r'\\W+',content) \n",
    "        lower_words=[word.lower() for word in Split_String] \n",
    "        length_filtered=[word for word in lower_words if len(word)>1]\n",
    "    \n",
    "    ### calculate total number or words\n",
    "        Total_Words=len(length_filtered)\n",
    "        Words_List_for_Each_Emotion=words_list_for_each_emotion(length_filtered)\n",
    "    \n",
    "        result_list=[]\n",
    "        for i in EMOTIONS:\n",
    "            result={}\n",
    "            example_words=[get_common_words_list(value)[:3] for key,value in Words_List_for_Each_Emotion.items() if key==i]\n",
    "            result['EMOTION']=i\n",
    "            result['PERCENT']= len(Words_List_for_Each_Emotion[i])/Total_Words\n",
    "            result['EXAMPLE WORDS']=example_words[0]\n",
    "            result['name'] = name\n",
    "            result_list.append(result)\n",
    "            result=sorted(result_list,key=lambda k:k['PERCENT'],reverse=True)\n",
    "            result = pd.DataFrame(result)\n",
    "            res = res.append(result)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SentimentSetup.py\n",
    "\"\"\"\n",
    "# support function 1\n",
    "def words_with_specific_emotion(list_of_split_words,emotion):\n",
    "    '''Produce a list that include the words that contain a specific emotion\n",
    "       Parameters: list_of_split_words (String): A list with split words \n",
    "                   emotion(string): the emotion words in EMOTIONS list\n",
    "       Returns: list: the words in the string with one certain kind of emotion'''\n",
    "    Look_Up=[SENTIMENTS.get(word) for word in list_of_split_words] #get the emotion list of every word in the list \n",
    "    Combine=list(zip(list_of_split_words,Look_Up)) # zip the emotion list with word in one list \n",
    "    Words_With_Specific_Emotion=[line[0] for line in Combine if line[1] is not None and line[1].get(emotion)==1 ]\n",
    "    return Words_With_Specific_Emotion #find the words in a specific emotion\n",
    "\n",
    "# support function 2\n",
    "def words_list_for_each_emotion(Split_Test_String):\n",
    "    '''Produce a disctionary with emotion words as keys and words list having that emotion as values\n",
    "       Parameters: Split_Test_String (String): A list with split words\n",
    "       Returns: list-the  most common words in the input list'''\n",
    "    matching_words=[words_with_specific_emotion(Split_Test_String,emotion) for emotion in EMOTIONS]\n",
    "    distinct_matching=[i for i in matching_words]\n",
    "    return {emotion:matching_word for (emotion,matching_word) in zip(EMOTIONS,distinct_matching)}\n",
    "\n",
    "# support function 3 \n",
    "def get_common_words_list(wordlist):\n",
    "    '''Produce a list with the most common words of the input list\n",
    "       Parameters: wordlist (string): \n",
    "       Returns: dict: the key-values pairs of emotions word and its corresponding words in the string'''\n",
    "    wordfreq=list(zip(wordlist,[wordlist.count(w) for w in wordlist]))\n",
    "    wordfreq_sort=list(set(sorted(wordfreq,key=lambda freq: freq[1], reverse=True)))\n",
    "    new_word_freq_sort=sorted(wordfreq_sort,key=lambda freq: freq[1], reverse=True)\n",
    "    return [i[0] for i in new_word_freq_sort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualization.py\n",
    "\"\"\"\n",
    "def visualize(EMOTION_ARRAY):\n",
    "    import altair as alt\n",
    "    alt.renderers.enable('notebook')\n",
    "\n",
    "    #input_dropdown = alt.binding_select(options= top_critics)\n",
    "    #selection = alt.selection_single(fields=['name'], bind=input_dropdown, name='Critic of ')\n",
    "    #color = alt.condition(selection,\n",
    "                        #alt.Color('critic:N', legend=None),\n",
    "                        #alt.value('lightgray'))\n",
    "    chart_final = alt.Chart(EMOTION_ARRAY).mark_bar().encode(\n",
    "         x='PERCENT:Q',\n",
    "         y=alt.Y(\n",
    "            'EMOTION:N',\n",
    "            sort=alt.EncodingSortField(field='PERCENT', op='count', order='ascending')\n",
    "            ),\n",
    "        facet='name:N',\n",
    "        color='EMOTION:N',\n",
    "        tooltip='PERCENT:Q',\n",
    "        ).properties(\n",
    "        width=150,\n",
    "        height=150,\n",
    "        title = 'Sentiment for Top 5 Critics',\n",
    "        columns=5,\n",
    "        )\n",
    "    chart_final.save('finalchart.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input a year of interest to see critic activity that year: \n",
      "2009\n",
      "['Stephanie Zacharek', 'Kyle Smith', 'Ben Lyons', 'Ben Mankiewicz', 'Stephen Whitty']\n",
      "               critic                                              quote\n",
      "0           Ben Lyons  A terrific twist, but goes wasted in a movie t...\n",
      "1      Ben Mankiewicz  I just don't think there was enough drama in t...\n",
      "2          Kyle Smith  This movie knows exactly what it is: Gonzo sil...\n",
      "3  Stephanie Zacharek  Ninja Assassin lives in the moment, a visceral...\n",
      "4      Stephen Whitty  A Perfect Getaway is one of those very clever ...\n"
     ]
    }
   ],
   "source": [
    "'''LOAD DATA'''\n",
    "MOVIES = pd.read_csv(\"../data/movies.dat\", delimiter='\\t')\n",
    "REVIEWS = pd.read_csv('../data/reviews.csv')\n",
    "\n",
    "'''OVERALL LOOK'''\n",
    "start_year = 1990\n",
    "end_year = 2013\n",
    "SUB_MOVIES = clean_movies(MOVIES)\n",
    "draw_trend_line_median_year(SUB_MOVIES,start_year,end_year)\n",
    "\n",
    "'''CLEAN AND MERGE DATA'''\n",
    "REVIEWS_CLEAN = clean_reviews(REVIEWS)\n",
    "REVIEWS_MERGE = merge_movies_reviews(REVIEWS,SUB_MOVIES)\n",
    "\n",
    "'''TOP CRITICS IN YEAR OF INTEREST'''\n",
    "print('Please input a year of interest to see critic activity that year: ')\n",
    "interest_year = int(input())\n",
    "top_critics = top5_critic_per_year(REVIEWS_MERGE,interest_year)\n",
    "print(top_critics)\n",
    "\n",
    "'''GRAB CRITIC REVIEWS'''\n",
    "QUOTES = grab_quotes(REVIEWS_MERGE,top_critics,interest_year)\n",
    "print(QUOTES)\n",
    "\n",
    "'''ANALYZE QUOTES'''\n",
    "EMOTION_ARRAY = analyze_quote(QUOTES,top_critics)\n",
    "visualize(EMOTION_ARRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
